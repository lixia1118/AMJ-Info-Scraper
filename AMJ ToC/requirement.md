我想爬取一个网站的数据，该网站是AMJ期刊每期论文的基础信息，比如说第47期第5卷的网站是https://journals.aom.org/toc/amj/47/5，最早是https://journals.aom.org/toc/amj/1/1，每期最多是6卷。

我需要爬取的数据有：
1. 每期每篇论文的标题
2. 每期每篇论文的作者
3. 每期每篇论文的DOI号
4. 每期每篇论文的链接
我想将这些信息保存到本地，并且保存为xlsx文件
请帮我用python写一个爬虫
